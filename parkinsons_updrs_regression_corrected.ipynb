{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a74b35a",
   "metadata": {},
   "source": [
    "# Parkinson’s UPDRS Progression Modeling (Regression)\n",
    "\n",
    "This notebook adapts your dataset (columns like `visit_month`, `updrs_1..4`) into a **regression ML project**.\n",
    "\n",
    "## What you have\n",
    "- Longitudinal clinical visits per patient\n",
    "- Targets you can predict: `updrs_1`, `updrs_2`, `updrs_3`, `updrs_4` (severity scores)\n",
    "\n",
    "## What we’ll do\n",
    "1. Load the CSV from `data/`\n",
    "2. Basic EDA + sanity checks\n",
    "3. Create a regression target (default: `updrs_3`)\n",
    "4. Split data (group-aware split by `patient_id` recommended)\n",
    "5. Train models (LinearRegression, Ridge, RandomForestRegressor)\n",
    "6. Evaluate (MAE, RMSE, R²) + plots\n",
    "\n",
    "**Tip:** If you want to predict a different UPDRS score, change `TARGET = 'updrs_3'`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4fa0d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install numpy pandas scikit-learn matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c6dbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports ready\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 140)\n",
    "\n",
    "print('Imports ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e089ff7",
   "metadata": {},
   "source": [
    "## 1) Load data\n",
    "Put your CSV inside `data/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48fc6980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: data/supplemental_clinical_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>visit_month</th>\n",
       "      <th>updrs_1</th>\n",
       "      <th>updrs_2</th>\n",
       "      <th>updrs_3</th>\n",
       "      <th>updrs_4</th>\n",
       "      <th>upd23b_clinical_state_on_medication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35_0</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35_36</td>\n",
       "      <td>35</td>\n",
       "      <td>36</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75_0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75_36</td>\n",
       "      <td>75</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>On</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155_0</td>\n",
       "      <td>155</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  visit_id  patient_id  visit_month  updrs_1  updrs_2  updrs_3  updrs_4 upd23b_clinical_state_on_medication\n",
       "0     35_0          35            0      5.0      3.0     16.0      0.0                                 NaN\n",
       "1    35_36          35           36      6.0      4.0     20.0      0.0                                 NaN\n",
       "2     75_0          75            0      4.0      6.0     26.0      0.0                                 NaN\n",
       "3    75_36          75           36      1.0      8.0     38.0      0.0                                  On\n",
       "4    155_0         155            0      NaN      NaN      0.0      NaN                                 NaN"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_DIR = 'data'\n",
    "csv_files = sorted(glob.glob(os.path.join(DATA_DIR, '*.csv')))\n",
    "if not csv_files:\n",
    "    raise FileNotFoundError(f\"No CSV found in '{DATA_DIR}/'. Put your dataset CSV there.\")\n",
    "\n",
    "csv_path = csv_files[0]\n",
    "print('Using:', csv_path)\n",
    "df = pd.read_csv(csv_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb977d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (2223, 8)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2223 entries, 0 to 2222\n",
      "Data columns (total 8 columns):\n",
      " #   Column                               Non-Null Count  Dtype  \n",
      "---  ------                               --------------  -----  \n",
      " 0   visit_id                             2223 non-null   object \n",
      " 1   patient_id                           2223 non-null   int64  \n",
      " 2   visit_month                          2223 non-null   int64  \n",
      " 3   updrs_1                              2010 non-null   float64\n",
      " 4   updrs_2                              2009 non-null   float64\n",
      " 5   updrs_3                              2218 non-null   float64\n",
      " 6   updrs_4                              1295 non-null   float64\n",
      " 7   upd23b_clinical_state_on_medication  1122 non-null   object \n",
      "dtypes: float64(4), int64(2), object(2)\n",
      "memory usage: 139.1+ KB\n"
     ]
    }
   ],
   "source": [
    "print('Shape:', df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68626bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "upd23b_clinical_state_on_medication    1101\n",
       "updrs_4                                 928\n",
       "updrs_2                                 214\n",
       "updrs_1                                 213\n",
       "updrs_3                                   5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick missing values overview\n",
    "missing = df.isna().sum().sort_values(ascending=False)\n",
    "missing[missing > 0].head(20) if (missing > 0).any() else 'No missing values found.'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e11389",
   "metadata": {},
   "source": [
    "## 2) Choose a target\n",
    "Your dataset doesn’t have a `status` label (healthy vs PD). Instead, it has **UPDRS severity scores**.\n",
    "\n",
    "We’ll default to predicting **motor severity**: `updrs_3`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd9fac65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    2218.000000\n",
       "mean       22.917944\n",
       "std        12.342596\n",
       "min         0.000000\n",
       "25%        14.000000\n",
       "50%        22.000000\n",
       "75%        31.000000\n",
       "max        72.000000\n",
       "Name: updrs_3, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGET = 'updrs_3'  # change to 'updrs_1' / 'updrs_2' / 'updrs_4' if you want\n",
    "\n",
    "required_cols = {'patient_id', 'visit_month', TARGET}\n",
    "missing_req = required_cols - set(df.columns)\n",
    "if missing_req:\n",
    "    raise ValueError(f\"Missing required columns: {missing_req}. Your columns: {list(df.columns)[:25]}...\")\n",
    "\n",
    "df[TARGET].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b09ca90",
   "metadata": {},
   "source": [
    "## 3) Feature engineering\n",
    "\n",
    "Basic approach:\n",
    "- Use numeric predictors like `visit_month`, other UPDRS scores, and medication state columns\n",
    "- Drop ID columns from features (`visit_id`, `patient_id`)\n",
    "\n",
    "### Leakage warning\n",
    "If you predict `updrs_3` and include `updrs_3` in features, that’s cheating. We will drop the target from X.\n",
    "\n",
    "Also, **including other UPDRS scores (`updrs_1`, `updrs_2`, `updrs_4`) may be OK** depending on your goal:\n",
    "- If you want to estimate `updrs_3` from other clinical measures taken at the same visit, it’s fine.\n",
    "- If you want to forecast future `updrs_3`, you should use only past information.\n",
    "\n",
    "This notebook does the simpler “same-visit” regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9150384b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_month</th>\n",
       "      <th>updrs_1</th>\n",
       "      <th>updrs_2</th>\n",
       "      <th>updrs_4</th>\n",
       "      <th>upd23b_clinical_state_on_medication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>On</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   visit_month  updrs_1  updrs_2  updrs_4 upd23b_clinical_state_on_medication\n",
       "0            0      5.0      3.0      0.0                                 NaN\n",
       "1           36      6.0      4.0      0.0                                 NaN\n",
       "2            0      4.0      6.0      0.0                                 NaN\n",
       "3           36      1.0      8.0      0.0                                  On\n",
       "4            0      NaN      NaN      NaN                                 NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build X/y\n",
    "drop_cols = ['visit_id'] if 'visit_id' in df.columns else []\n",
    "\n",
    "y = df[TARGET].astype(float)\n",
    "X = df.drop(columns=[TARGET] + drop_cols)\n",
    "\n",
    "# Keep patient_id for group split, but NOT as a feature\n",
    "groups = X['patient_id']\n",
    "\n",
    "# Drop identifiers from features\n",
    "X = X.drop(columns=['patient_id'])\n",
    "\n",
    "# ---- Fix non-numeric columns ----\n",
    "# The medication-state column can contain strings like \"On\"/\"Off\" plus NaNs.\n",
    "# Convert to numeric so the median imputer + models can run.\n",
    "med_col = 'upd23b_clinical_state_on_medication'\n",
    "if med_col in X.columns:\n",
    "    X[med_col] = (\n",
    "        X[med_col]\n",
    "        .astype('string')\n",
    "        .str.strip()\n",
    "        .map({'On': 1, 'Off': 0})\n",
    "        .fillna(0)\n",
    "        .astype(float)\n",
    "    )\n",
    "\n",
    "# If any object columns remain, show them (you can decide how to encode them)\n",
    "obj_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "if obj_cols:\n",
    "    print('Warning: non-numeric feature columns still present:', obj_cols)\n",
    "\n",
    "X.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ---- FIX NON-NUMERIC COLUMNS (AUTO-GENERATED FIX) ----\n",
    "\n",
    "# Drop visit_id if present\n",
    "if 'visit_id' in X.columns:\n",
    "    X = X.drop(columns=['visit_id'])\n",
    "\n",
    "# Encode medication state: On=1, Off/NaN=0\n",
    "if 'upd23b_clinical_state_on_medication' in X.columns:\n",
    "    X['upd23b_clinical_state_on_medication'] = (\n",
    "        X['upd23b_clinical_state_on_medication']\n",
    "        .map({'On': 1, 'Off': 0})\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "X.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e206e62",
   "metadata": {},
   "source": [
    "## 4) Train/test split\n",
    "\n",
    "Because you have repeated visits per patient, a random split can leak patient information.\n",
    "\n",
    "**Better:** Group-aware split so the same patient doesn’t appear in both train and test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecda5f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1774, 5), (449, 5))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, test_idx = next(gss.split(X, y, groups=groups))\n",
    "\n",
    "X_train, X_test = X.iloc[train_idx].copy(), X.iloc[test_idx].copy()\n",
    "y_train, y_test = y.iloc[train_idx].copy(), y.iloc[test_idx].copy()\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0557ef1",
   "metadata": {},
   "source": [
    "## 5) Models\n",
    "\n",
    "We’ll try:\n",
    "- LinearRegression (baseline)\n",
    "- Ridge (helps with multicollinearity)\n",
    "- RandomForestRegressor (nonlinear, often strong baseline)\n",
    "\n",
    "### Preprocessing pipeline\n",
    "- Impute missing values (median)\n",
    "- Standardize (for linear models)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0516ed4e-4913-4417-a898-76170f830205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert On/Off strings to 1/0 if present\n",
    "for col in X.columns:\n",
    "    if X[col].dtype == \"object\":\n",
    "        # common mapping for medication state\n",
    "        X[col] = X[col].str.strip().map({\"On\": 1, \"Off\": 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18c0cc43-219c-4334-a062-1d81905969b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Identify column types\n",
    "num_cols = X.select_dtypes(include=[\"number\"]).columns\n",
    "cat_cols = X.select_dtypes(exclude=[\"number\"]).columns\n",
    "\n",
    "numeric_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", numeric_pipe, num_cols),\n",
    "    (\"cat\", categorical_pipe, cat_cols)\n",
    "])\n",
    "\n",
    "linear = Pipeline([(\"preprocess\", preprocess), (\"model\", LinearRegression())])\n",
    "ridge  = Pipeline([(\"preprocess\", preprocess), (\"model\", Ridge(alpha=1.0, random_state=42))])\n",
    "rf     = Pipeline([(\"preprocess\", preprocess), (\"model\", RandomForestRegressor(n_estimators=400, random_state=42, n_jobs=-1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "124c3fac-2ba9-4d77-b21b-a57172d8d327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>visit_id</th>\n",
       "      <th>upd23b_clinical_state_on_medication</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35_0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35_36</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>75_0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75_36</td>\n",
       "      <td>On</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>155_0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  visit_id upd23b_clinical_state_on_medication\n",
       "0     35_0                                 NaN\n",
       "1    35_36                                 NaN\n",
       "2     75_0                                 NaN\n",
       "3    75_36                                  On\n",
       "4    155_0                                 NaN"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select_dtypes(include=[\"object\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ec38b34-e204-46f3-825e-b77a37bb4603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "visit_month                              int64\n",
       "updrs_1                                float64\n",
       "updrs_2                                float64\n",
       "updrs_4                                float64\n",
       "upd23b_clinical_state_on_medication    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- FIX NON-NUMERIC COLUMNS ----\n",
    "\n",
    "# 1) Drop visit_id (identifier, not useful for ML)\n",
    "if 'visit_id' in X.columns:\n",
    "    X = X.drop(columns=['visit_id'])\n",
    "\n",
    "# 2) Encode medication state: On = 1, Off/NaN = 0\n",
    "if 'upd23b_clinical_state_on_medication' in X.columns:\n",
    "    X['upd23b_clinical_state_on_medication'] = (\n",
    "        X['upd23b_clinical_state_on_medication']\n",
    "        .map({'On': 1, 'Off': 0})\n",
    "        .fillna(0)\n",
    "    )\n",
    "\n",
    "# Sanity check\n",
    "X.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cad27f7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'On'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 38\u001b[0m\n\u001b[1;32m     35\u001b[0m pred_store \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m---> 38\u001b[0m     model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[1;32m     39\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     40\u001b[0m     mae, rmse, r2 \u001b[38;5;241m=\u001b[39m eval_regression(y_test, preds)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.13/site-packages/sklearn/pipeline.py:655\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    649\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `transform_input` parameter can only be set if metadata \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    650\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrouting is enabled. You can enable metadata routing using \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    651\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`sklearn.set_config(enable_metadata_routing=True)`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    652\u001b[0m     )\n\u001b[1;32m    654\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 655\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X, y, routed_params, raw_params\u001b[38;5;241m=\u001b[39mparams)\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    657\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.13/site-packages/sklearn/pipeline.py:589\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, routed_params, raw_params)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[1;32m    583\u001b[0m step_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_metadata_for_step(\n\u001b[1;32m    584\u001b[0m     step_idx\u001b[38;5;241m=\u001b[39mstep_idx,\n\u001b[1;32m    585\u001b[0m     step_params\u001b[38;5;241m=\u001b[39mrouted_params[name],\n\u001b[1;32m    586\u001b[0m     all_params\u001b[38;5;241m=\u001b[39mraw_params,\n\u001b[1;32m    587\u001b[0m )\n\u001b[0;32m--> 589\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m fit_transform_one_cached(\n\u001b[1;32m    590\u001b[0m     cloned_transformer,\n\u001b[1;32m    591\u001b[0m     X,\n\u001b[1;32m    592\u001b[0m     y,\n\u001b[1;32m    593\u001b[0m     weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    594\u001b[0m     message_clsname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    595\u001b[0m     message\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(step_idx),\n\u001b[1;32m    596\u001b[0m     params\u001b[38;5;241m=\u001b[39mstep_params,\n\u001b[1;32m    597\u001b[0m )\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.13/site-packages/joblib/memory.py:326\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.13/site-packages/sklearn/pipeline.py:1540\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m   1539\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1540\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit_transform(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\n\u001b[1;32m   1541\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1542\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   1543\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m   1544\u001b[0m         )\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.13/site-packages/sklearn/utils/_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 316\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    318\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    321\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    322\u001b[0m         )\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.13/site-packages/sklearn/base.py:897\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    895\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m--> 897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.13/site-packages/sklearn/base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1363\u001b[0m     )\n\u001b[1;32m   1364\u001b[0m ):\n\u001b[0;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.13/site-packages/sklearn/impute/_base.py:452\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    434\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    436\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the imputer on `X`.\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \n\u001b[1;32m    438\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 452\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_input(X, in_fit\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# otherwise\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/miniconda3/lib/python3.13/site-packages/sklearn/impute/_base.py:377\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not convert\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n\u001b[1;32m    372\u001b[0m     new_ve \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    373\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m strategy with non-numeric data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    374\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, ve\n\u001b[1;32m    375\u001b[0m         )\n\u001b[1;32m    376\u001b[0m     )\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ve\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot use median strategy with non-numeric data:\ncould not convert string to float: 'On'"
     ]
    }
   ],
   "source": [
    "def eval_regression(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    return mae, rmse, r2\n",
    "\n",
    "linear = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "ridge = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', Ridge(alpha=1.0, random_state=42))\n",
    "])\n",
    "\n",
    "rf = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('model', RandomForestRegressor(\n",
    "        n_estimators=400,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])\n",
    "\n",
    "models = {\n",
    "    'LinearRegression': linear,\n",
    "    'Ridge': ridge,\n",
    "    'RandomForest': rf\n",
    "}\n",
    "\n",
    "results = []\n",
    "pred_store = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    mae, rmse, r2 = eval_regression(y_test, preds)\n",
    "    results.append((name, mae, rmse, r2))\n",
    "    pred_store[name] = preds\n",
    "\n",
    "pd.DataFrame(results, columns=['model', 'MAE', 'RMSE', 'R2']).sort_values('MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4a2c26",
   "metadata": {},
   "source": [
    "## 6) Plot predicted vs actual\n",
    "Good models should align near the diagonal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136e07c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_name = pd.DataFrame(results, columns=['model','MAE','RMSE','R2']).sort_values('MAE').iloc[0]['model']\n",
    "best_preds = pred_store[best_name]\n",
    "print('Best by MAE:', best_name)\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.scatter(y_test, best_preds, alpha=0.6)\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title(f'Predicted vs Actual ({best_name}) - Target: {TARGET}')\n",
    "\n",
    "min_v = min(y_test.min(), best_preds.min())\n",
    "max_v = max(y_test.max(), best_preds.max())\n",
    "plt.plot([min_v, max_v], [min_v, max_v])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a1804a",
   "metadata": {},
   "source": [
    "## 7) Feature importance (RandomForest)\n",
    "\n",
    "This is quick and useful to learn what drives predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bc4098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importances from the fitted RF inside the pipeline\n",
    "rf_fitted = models['RandomForest']\n",
    "rf_fitted.fit(X_train, y_train)\n",
    "rf_model = rf_fitted.named_steps['model']\n",
    "\n",
    "importances = pd.Series(rf_model.feature_importances_, index=X_train.columns).sort_values(ascending=False)\n",
    "importances.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67bb67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "importances.head(15).sort_values().plot(kind='barh')\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Top 15 Feature Importances (RandomForest)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb4bda5",
   "metadata": {},
   "source": [
    "## 8) Next upgrades (optional)\n",
    "\n",
    "### Make it a true forecasting problem\n",
    "Instead of predicting UPDRS at the same visit, create a target like:\n",
    "- `updrs_3_next = updrs_3` shifted to the next visit per patient\n",
    "and train using only information from the current/previous visits.\n",
    "\n",
    "### Better evaluation\n",
    "- Use GroupKFold cross-validation (patient-level)\n",
    "- Add Gradient Boosting models (XGBoost/LightGBM if you want)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}